{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d80a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18ed44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is Loaded\n"
     ]
    }
   ],
   "source": [
    "paths = []\n",
    "labels = []\n",
    "for dirname, _, filenames in os.walk(\"D:\\DS\\Song Emotion Recognition\\Speech Recog\\TESS Toronto emotional speech set data\"):\n",
    "    for filename in filenames:\n",
    "        paths.append(os.path.join(dirname, filename))\n",
    "        label = filename.split('_')[-1]\n",
    "        label = label.split('.')[0]\n",
    "        labels.append(label.lower())\n",
    "    if len(paths) == 2800:\n",
    "        print('Dataset is Loaded')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1301a1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  label\n",
       "0  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  angry\n",
       "1  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  angry\n",
       "2  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  angry\n",
       "3  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  angry\n",
       "4  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  angry"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'audio': paths, 'label': labels}\n",
    "df = pd.DataFrame(data=d)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "767b586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = shuffle(df)\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fb5dbf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio    label\n",
       "0  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    happy\n",
       "1  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  neutral\n",
       "2  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  neutral\n",
       "3  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    angry\n",
       "4  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56ec8ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "happy      400\n",
       "neutral    400\n",
       "angry      400\n",
       "disgust    400\n",
       "ps         400\n",
       "sad        400\n",
       "fear       400\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a4ae37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feat(filename):\n",
    "    y, sr = librosa.load(filename, duration=3, offset=0.5)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    return mfcc\n",
    "x_ef = df['audio'].apply(lambda x: extract_feat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5caa5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b57deca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f78d61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [x for x in x_ef]\n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a1953a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe006eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 40, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = np.expand_dims(X,-1)\n",
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f209bab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-307.82648  ,   28.52483  ,  -29.723549 , ...,   -1.8848119,\n",
       "          -5.2645826,   -2.5169687],\n",
       "       [-387.16562  ,  103.01318  ,  -13.825495 , ...,   27.681023 ,\n",
       "           7.993047 ,   -3.2593598],\n",
       "       [-539.151    ,  124.19071  ,   31.638233 , ...,   35.975502 ,\n",
       "          16.460072 ,    1.4680022],\n",
       "       ...,\n",
       "       [-415.20203  ,  130.79768  ,   27.871264 , ...,   12.0982065,\n",
       "          14.209072 ,   15.923146 ],\n",
       "       [-525.6591   ,  109.39722  ,   19.225296 , ...,   39.64732  ,\n",
       "          29.605762 ,   18.953228 ],\n",
       "       [-297.05402  ,   25.756916 ,   13.8266   , ...,   -1.2488215,\n",
       "          -1.764624 ,    3.691428 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a16954be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "y = enc.fit_transform(df[['label']])\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3d83374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "deeb04d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2800, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.toarray()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4caa5928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdfcff57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256)               264192    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 305,799\n",
      "Trainable params: 305,799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    LSTM(256, return_sequences=False, input_shape=(40,1)),\n",
    "    Dropout(0.2),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(7, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b353d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1af6329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2800, 40) (2240, 40) (560, 40) (2240,) (560,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)\n",
    "print(X.shape, x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb810fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "35/35 [==============================] - 4s 83ms/step - loss: 1.1917 - accuracy: 0.5344 - val_loss: 0.4964 - val_accuracy: 0.8429\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 3s 73ms/step - loss: 0.4091 - accuracy: 0.8589 - val_loss: 0.2085 - val_accuracy: 0.9232\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.1966 - accuracy: 0.9379 - val_loss: 0.1739 - val_accuracy: 0.9393\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.1569 - accuracy: 0.9504 - val_loss: 0.1844 - val_accuracy: 0.9518\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 3s 78ms/step - loss: 0.1816 - accuracy: 0.9429 - val_loss: 0.1783 - val_accuracy: 0.9518\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 3s 73ms/step - loss: 0.1083 - accuracy: 0.9670 - val_loss: 0.1908 - val_accuracy: 0.9375\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.1194 - accuracy: 0.9670 - val_loss: 0.1571 - val_accuracy: 0.9536\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.1081 - accuracy: 0.9665 - val_loss: 0.2524 - val_accuracy: 0.9321\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.1559 - accuracy: 0.9513 - val_loss: 0.1266 - val_accuracy: 0.9607\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0669 - accuracy: 0.9830 - val_loss: 0.2090 - val_accuracy: 0.9482\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0755 - accuracy: 0.9746 - val_loss: 0.0954 - val_accuracy: 0.9696\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0598 - accuracy: 0.9799 - val_loss: 0.1359 - val_accuracy: 0.9643\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0727 - accuracy: 0.9768 - val_loss: 0.0931 - val_accuracy: 0.9696\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0663 - accuracy: 0.9754 - val_loss: 0.1148 - val_accuracy: 0.9661\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.0480 - accuracy: 0.9857 - val_loss: 0.0956 - val_accuracy: 0.9679\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.0519 - accuracy: 0.9848 - val_loss: 0.1044 - val_accuracy: 0.9679\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0507 - accuracy: 0.9830 - val_loss: 0.1608 - val_accuracy: 0.9536\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.0541 - accuracy: 0.9821 - val_loss: 0.1790 - val_accuracy: 0.9643\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0681 - accuracy: 0.9754 - val_loss: 0.0823 - val_accuracy: 0.9821\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 0.0784 - val_accuracy: 0.9804\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0322 - accuracy: 0.9906 - val_loss: 0.0923 - val_accuracy: 0.9732\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.1152 - val_accuracy: 0.9696\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0408 - accuracy: 0.9888 - val_loss: 0.1808 - val_accuracy: 0.9607\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 2s 70ms/step - loss: 0.0733 - accuracy: 0.9772 - val_loss: 0.0965 - val_accuracy: 0.9750\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0354 - accuracy: 0.9906 - val_loss: 0.1065 - val_accuracy: 0.9714\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0346 - accuracy: 0.9888 - val_loss: 0.0948 - val_accuracy: 0.9750\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0387 - accuracy: 0.9875 - val_loss: 0.1824 - val_accuracy: 0.9589\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0429 - accuracy: 0.9857 - val_loss: 0.1331 - val_accuracy: 0.9661\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0420 - accuracy: 0.9857 - val_loss: 0.1422 - val_accuracy: 0.9714\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0341 - accuracy: 0.9911 - val_loss: 0.0823 - val_accuracy: 0.9714\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0134 - accuracy: 0.9946 - val_loss: 0.1031 - val_accuracy: 0.9768\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 3s 73ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.0916 - val_accuracy: 0.9732\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.1089 - val_accuracy: 0.9804\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0112 - accuracy: 0.9960 - val_loss: 0.1385 - val_accuracy: 0.9679\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0703 - accuracy: 0.9821 - val_loss: 0.1676 - val_accuracy: 0.9571\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0370 - accuracy: 0.9920 - val_loss: 0.0857 - val_accuracy: 0.9804\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0276 - accuracy: 0.9906 - val_loss: 0.1043 - val_accuracy: 0.9750\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 2s 72ms/step - loss: 0.0323 - accuracy: 0.9897 - val_loss: 0.1524 - val_accuracy: 0.9696\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0270 - accuracy: 0.9924 - val_loss: 0.0847 - val_accuracy: 0.9821\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0229 - accuracy: 0.9915 - val_loss: 0.0875 - val_accuracy: 0.9804\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 0.0555 - val_accuracy: 0.9857\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0915 - val_accuracy: 0.9821\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 2s 72ms/step - loss: 0.0024 - accuracy: 0.9996 - val_loss: 0.0793 - val_accuracy: 0.9804\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.1713 - val_accuracy: 0.9607\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0532 - accuracy: 0.9871 - val_loss: 0.0867 - val_accuracy: 0.9786\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0212 - accuracy: 0.9946 - val_loss: 0.1202 - val_accuracy: 0.9786\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 3s 72ms/step - loss: 0.0223 - accuracy: 0.9920 - val_loss: 0.0797 - val_accuracy: 0.9750\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0447 - accuracy: 0.9857 - val_loss: 0.1011 - val_accuracy: 0.9696\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 3s 73ms/step - loss: 0.0203 - accuracy: 0.9946 - val_loss: 0.1112 - val_accuracy: 0.9679\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 2s 71ms/step - loss: 0.0247 - accuracy: 0.9920 - val_loss: 0.2038 - val_accuracy: 0.9554\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, y, validation_split=0.2, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c61c8b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = list(range(50))\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, label='train accuracy')\n",
    "plt.plot(epochs, val_acc, label='val accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1f48b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_format(filepath):\n",
    "    pred_extraction = extract_feat(filepath)\n",
    "    fomat = np.array(pred_extraction)\n",
    "    fomat = fomat.reshape(-1,1)\n",
    "    return fomat\n",
    "#df['audio'][0]\n",
    "#to_pred = to_format(df['audio'][0])\n",
    "#type(to_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bd235649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[              -307.826477],\n",
       "       [                28.524830],\n",
       "       [               -29.723549],\n",
       "       [                33.847157],\n",
       "       [               -22.056015],\n",
       "       [                10.576652],\n",
       "       [                -6.646882],\n",
       "       [                -9.984513],\n",
       "       [                 2.618359],\n",
       "       [                -1.464032],\n",
       "       [               -10.082344],\n",
       "       [                12.475165],\n",
       "       [                -9.398715],\n",
       "       [                10.975546],\n",
       "       [                -3.751351],\n",
       "       [                -2.576631],\n",
       "       [                -3.866509],\n",
       "       [                -1.950035],\n",
       "       [               -10.655766],\n",
       "       [                -1.331545],\n",
       "       [                -8.847979],\n",
       "       [                -5.099771],\n",
       "       [                -3.584106],\n",
       "       [                 7.097256],\n",
       "       [                10.801182],\n",
       "       [                18.593822],\n",
       "       [                12.310085],\n",
       "       [                13.593747],\n",
       "       [                 5.839727],\n",
       "       [                 7.384404],\n",
       "       [                 3.069120],\n",
       "       [                 6.511447],\n",
       "       [                 1.259558],\n",
       "       [                 3.612061],\n",
       "       [                -2.596259],\n",
       "       [                 4.041758],\n",
       "       [                 1.774188],\n",
       "       [                -1.884812],\n",
       "       [                -5.264583],\n",
       "       [                -2.516969]], dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pred = to_format(df['audio'][0])\n",
    "to_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7d2ac0d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 1)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b2ae5cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 40)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pred_transpose = to_pred.T\n",
    "to_pred_transpose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a2c7beca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(to_pred_transpose)\n",
    "print(np.argmax(y_pred,axis= 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4a4c9727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[                 0.979089,                  0.000084,\n",
       "                         0.003339,                  0.016881,\n",
       "                         0.000005,                  0.000554,\n",
       "                         0.000047]], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:25f}'.format})\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "087d0afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2780</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2784</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2785</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2789</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2791</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2792</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2794</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2795</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2796</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2797</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2798</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2799</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  audio    label\n",
       "2780  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust\n",
       "2781  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...       ps\n",
       "2782  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  neutral\n",
       "2783  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...     fear\n",
       "2784  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...       ps\n",
       "2785  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    happy\n",
       "2786  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    happy\n",
       "2787  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...     fear\n",
       "2788  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...       ps\n",
       "2789  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    happy\n",
       "2790  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    angry\n",
       "2791  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust\n",
       "2792  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...      sad\n",
       "2793  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust\n",
       "2794  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust\n",
       "2795  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    happy\n",
       "2796  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  neutral\n",
       "2797  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust\n",
       "2798  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  neutral\n",
       "2799  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    angry"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6ec86725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>ps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                audio    label\n",
       "0   D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    happy\n",
       "1   D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  neutral\n",
       "2   D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  neutral\n",
       "3   D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    angry\n",
       "4   D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust\n",
       "5   D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  neutral\n",
       "6   D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  neutral\n",
       "7   D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  neutral\n",
       "8   D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    happy\n",
       "9   D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    happy\n",
       "10  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...       ps\n",
       "11  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust\n",
       "12  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    angry\n",
       "13  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    angry\n",
       "14  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust\n",
       "15  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust\n",
       "16  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...  disgust\n",
       "17  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...      sad\n",
       "18  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    angry\n",
       "19  D:\\DS\\Song Emotion Recognition\\Speech Recog\\TE...    happy"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24045625",
   "metadata": {},
   "source": [
    "### 0 - Happy/Energetic/Angry, 1 - Disgust, 2 - Fear, 3 - Angry, 4 - Neutral, 5 - Pleasant Surprise, 6 - Sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "570577b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Function\n",
    "\n",
    "#Returns numerical features \n",
    "def feature_extraction(filepath):\n",
    "    y, sr = librosa.load(filepath, duration=3, offset=0.5)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    return mfcc\n",
    "\n",
    "#Returns converted format of the .wav file which can be used for prediction\n",
    "def format_converter(filepath):\n",
    "    pred_extraction = extract_feat(filepath)\n",
    "    fomat = np.array(pred_extraction)\n",
    "    fomat = fomat.reshape(-1,1)\n",
    "    return fomat\n",
    "\n",
    "#Predicts the emotion and returns integer corresponding to it\n",
    "#All compiled. Final function to be used\n",
    "#Can be modified to take model as an argument too. Using Globally declared model for testing\n",
    "def predict_emotion(filepath):\n",
    "    to_pred = format_converter(filepath)\n",
    "    to_pred = to_pred.T\n",
    "    y_pred = model.predict(to_pred)\n",
    "    emotion = np.argmax(y_pred,axis = 1)\n",
    "    return emotion, y_pred[emotion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b61e0678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3993a482-46ca-4116-922c-91eefa36eb8f/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://3993a482-46ca-4116-922c-91eefa36eb8f/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb6924",
   "metadata": {},
   "source": [
    "### How to use the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "851b49be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0], dtype=int64),\n",
       " array([[                 0.979089,                  0.000084,\n",
       "                          0.003339,                  0.016881,\n",
       "                          0.000005,                  0.000554,\n",
       "                          0.000047]], dtype=float32))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just run the function. \n",
    "predict_emotion(df['audio'][0])\n",
    "#Add switch case statement for "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "song",
   "language": "python",
   "name": "song"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
